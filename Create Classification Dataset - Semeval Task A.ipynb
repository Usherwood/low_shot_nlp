{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from collections import Counter\n",
    "import csv\n",
    "import math\n",
    "import gzip\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "from stan_data_imports.social.social_apis.twitter import TwitterAPI\n",
    "from stan_data_imports.social.twitter_import import create_twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "repo_dir = cwd.parent\n",
    "dataset_dir = repo_dir / \"datasets\" / \"semeval\"\n",
    "\n",
    "# Load task A\n",
    "subtask_dir = dataset_dir / \"Subtask_A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter-2013dev-A.txt\n",
      "twitter-2013test-A.txt\n",
      "twitter-2013train-A.txt\n",
      "twitter-2014sarcasm-A.txt\n",
      "twitter-2014test-A.txt\n",
      "twitter-2015test-A.txt\n",
      "twitter-2015train-A.txt\n",
      "twitter-2016dev-A.txt\n",
      "twitter-2016devtest-A.txt\n",
      "twitter-2016test-A.txt\n",
      "twitter-2016train-A.txt\n",
      "(50334, 2)\n",
      "(49570, 2)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for file in os.listdir(subtask_dir):\n",
    "    if file[-4:] == '.txt':\n",
    "        with open(subtask_dir / file) as f:\n",
    "            print(file)\n",
    "            data += f.readlines()\n",
    "data = [line.replace('\\n','').replace(' ','').split('\\t') for line in data]\n",
    "\n",
    "df_a = pd.DataFrame(data, columns=[\"ID\", \"Sentiment\", \"Junk\"])\n",
    "df_a[\"Sentiment\"] = df_a[\"Sentiment\"].replace(\"negative\",\"Negative\").replace(\"positive\", \"Positive\").replace(\"neutral\", \"Neutral\")\n",
    "df_a = df_a[[\"ID\", \"Sentiment\"]]\n",
    "print(df_a.shape)\n",
    "df_a.drop_duplicates(subset=[\"ID\"], inplace=True)\n",
    "print(df_a.shape)\n",
    "\n",
    "df_a.index = df_a[\"ID\"]\n",
    "df_a.drop(\"ID\", 1, inplace=True)\n",
    "map_a = df_a.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral     22202\n",
      "Positive    19636\n",
      "Negative     7732\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_a[\"Sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TwitterAPI()\n",
    "tweets_raw = api.fortify_twitter_tweets_batch(tweet_ids=df_a.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 35632\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Source</th>\n",
       "      <th>Url</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Date (GMT)</th>\n",
       "      <th>Date (Local)</th>\n",
       "      <th>Date (Local - Zone)</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>Bio</th>\n",
       "      <th>Profile Picture URL</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Profile Picture</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Number of Statuses</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Status Merged</th>\n",
       "      <th>Listed Count</th>\n",
       "      <th>Friends Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264110966025908224</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>TwitterAPI</td>\n",
       "      <td>https://twitter.com/statuses/264110966025908224</td>\n",
       "      <td>twitter.com24698721</td>\n",
       "      <td>2012-11-01 21:05:35+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Tonight Dr. Terrie Hale Scheckelhoff will be f...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>...</td>\n",
       "      <td>This is the official site for St. Catherine's ...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/958005546...</td>\n",
       "      <td>2619</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/958005546...</td>\n",
       "      <td>False</td>\n",
       "      <td>9597</td>\n",
       "      <td>2009-03-16 14:30:52+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>53</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263138318550700032</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>TwitterAPI</td>\n",
       "      <td>https://twitter.com/statuses/263138318550700032</td>\n",
       "      <td>twitter.com99380608</td>\n",
       "      <td>2012-10-30 04:40:38+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>@solz_b He's a true Niners fan, he brought it ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>...</td>\n",
       "      <td>Sup! Instagram: rodh80</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/514561570...</td>\n",
       "      <td>1499</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/514561570...</td>\n",
       "      <td>False</td>\n",
       "      <td>19213</td>\n",
       "      <td>2009-12-25 23:36:07+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>67</td>\n",
       "      <td>1626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250754443665080322</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>TwitterAPI</td>\n",
       "      <td>https://twitter.com/statuses/250754443665080322</td>\n",
       "      <td>twitter.com254373775</td>\n",
       "      <td>2012-09-26 00:31:32+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Who's going to Concords football game this Sat...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>...</td>\n",
       "      <td>ya love to see it</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/774637912...</td>\n",
       "      <td>657</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/774637912...</td>\n",
       "      <td>False</td>\n",
       "      <td>8708</td>\n",
       "      <td>2011-02-19 04:26:45+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262784216729796608</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>TwitterAPI</td>\n",
       "      <td>https://twitter.com/statuses/262784216729796608</td>\n",
       "      <td>twitter.com302369855</td>\n",
       "      <td>2012-10-29 05:13:34+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Up 20 points in my money league with Vernon Da...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>...</td>\n",
       "      <td>Hockey addict. Thinker of things. Many unpopul...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/583859560...</td>\n",
       "      <td>202</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/583859560...</td>\n",
       "      <td>False</td>\n",
       "      <td>13902</td>\n",
       "      <td>2011-05-21 02:28:33+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263642549640650752</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>TwitterAPI</td>\n",
       "      <td>https://twitter.com/statuses/263642549640650752</td>\n",
       "      <td>twitter.com37473785</td>\n",
       "      <td>2012-10-31 14:04:16+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>@gleekyspnluver @flippinstarkids It says on Wi...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>...</td>\n",
       "      <td>Gay. Tattooed. Crocheter. Music lover. Potty m...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/463076068...</td>\n",
       "      <td>85</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/463076068...</td>\n",
       "      <td>False</td>\n",
       "      <td>15499</td>\n",
       "      <td>2009-05-03 18:49:11+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>9</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweet ID       Domain      Source  \\\n",
       "0  264110966025908224  twitter.com  TwitterAPI   \n",
       "1  263138318550700032  twitter.com  TwitterAPI   \n",
       "2  250754443665080322  twitter.com  TwitterAPI   \n",
       "3  262784216729796608  twitter.com  TwitterAPI   \n",
       "4  263642549640650752  twitter.com  TwitterAPI   \n",
       "\n",
       "                                               Url             Author ID  \\\n",
       "0  https://twitter.com/statuses/264110966025908224   twitter.com24698721   \n",
       "1  https://twitter.com/statuses/263138318550700032   twitter.com99380608   \n",
       "2  https://twitter.com/statuses/250754443665080322  twitter.com254373775   \n",
       "3  https://twitter.com/statuses/262784216729796608  twitter.com302369855   \n",
       "4  https://twitter.com/statuses/263642549640650752   twitter.com37473785   \n",
       "\n",
       "                 Date (GMT) Date (Local) Date (Local - Zone)  \\\n",
       "0 2012-11-01 21:05:35+00:00         None                None   \n",
       "1 2012-10-30 04:40:38+00:00         None                None   \n",
       "2 2012-09-26 00:31:32+00:00         None                None   \n",
       "3 2012-10-29 05:13:34+00:00         None                None   \n",
       "4 2012-10-31 14:04:16+00:00         None                None   \n",
       "\n",
       "                                             Snippet  Sentiment  ...  \\\n",
       "0  Tonight Dr. Terrie Hale Scheckelhoff will be f...  Not Found  ...   \n",
       "1  @solz_b He's a true Niners fan, he brought it ...  Not Found  ...   \n",
       "2  Who's going to Concords football game this Sat...  Not Found  ...   \n",
       "3  Up 20 points in my money league with Vernon Da...  Not Found  ...   \n",
       "4  @gleekyspnluver @flippinstarkids It says on Wi...  Not Found  ...   \n",
       "\n",
       "                                                 Bio  \\\n",
       "0  This is the official site for St. Catherine's ...   \n",
       "1                             Sup! Instagram: rodh80   \n",
       "2                                  ya love to see it   \n",
       "3  Hockey addict. Thinker of things. Many unpopul...   \n",
       "4  Gay. Tattooed. Crocheter. Music lover. Potty m...   \n",
       "\n",
       "                                 Profile Picture URL  Follower Count  \\\n",
       "0  https://pbs.twimg.com/profile_images/958005546...            2619   \n",
       "1  https://pbs.twimg.com/profile_images/514561570...            1499   \n",
       "2  https://pbs.twimg.com/profile_images/774637912...             657   \n",
       "3  https://pbs.twimg.com/profile_images/583859560...             202   \n",
       "4  https://pbs.twimg.com/profile_images/463076068...              85   \n",
       "\n",
       "                                     Profile Picture  Verified  \\\n",
       "0  https://pbs.twimg.com/profile_images/958005546...     False   \n",
       "1  https://pbs.twimg.com/profile_images/514561570...     False   \n",
       "2  https://pbs.twimg.com/profile_images/774637912...     False   \n",
       "3  https://pbs.twimg.com/profile_images/583859560...     False   \n",
       "4  https://pbs.twimg.com/profile_images/463076068...     False   \n",
       "\n",
       "   Number of Statuses              Date Created Status Merged Listed Count  \\\n",
       "0                9597 2009-03-16 14:30:52+00:00            []           53   \n",
       "1               19213 2009-12-25 23:36:07+00:00            []           67   \n",
       "2                8708 2011-02-19 04:26:45+00:00            []            0   \n",
       "3               13902 2011-05-21 02:28:33+00:00            []            1   \n",
       "4               15499 2009-05-03 18:49:11+00:00            []            9   \n",
       "\n",
       "   Friends Count  \n",
       "0            386  \n",
       "1           1626  \n",
       "2            366  \n",
       "3            366  \n",
       "4            195  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_mentions = []\n",
    "twit_users = []\n",
    "\n",
    "for tweet in tweets_raw[0]:\n",
    "    twit_mentions.append(api.parse_tweet_to_twitter_mention(tweet))\n",
    "    \n",
    "for user in tweets_raw[1]:\n",
    "    twit_users.append(api.parse_user_to_twitter_user(user))\n",
    "    \n",
    "df_a_tweets = create_twitter_df(twit_mentions, twit_users)\n",
    "df_a_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_tweets[\"Sentiment\"] = df_a_tweets[\"Tweet ID\"].apply(lambda e: map_a[e]['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     16106\n",
       "Positive    14302\n",
       "Negative     5224\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a_tweets[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_a_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_round(x, base=.05, prec=2):\n",
    "    return round(base * round(float(x) / base), prec)\n",
    "\n",
    "\n",
    "def split_dataset_into_even_class_distributions(X_data, Y_data, train_size, test_size, mini_batch_size=32):\n",
    "    \"\"\"\n",
    "    Split a dataset into train, validate, and test sets that have the same distribution of classes as the original data.\n",
    "    Also this function ensures the resulting datasets are multiples of the mini_batch_size\n",
    "\n",
    "    :param X_data: Numpy 2d array or pandas dataframe, each row is a record\n",
    "    :param Y_data: Pandas Series, the categorial class labels\n",
    "    :param train_size: float 0-1, quantity of the original dataset to be in the train set (val is created from the residual)\n",
    "    :param test_size: float 0-1, quantity of the original dataset to be in the test set (val is created from the residual)\n",
    "    :param mini_batch_size: Int, the size of the mini batches to ensure each dataset is a multiple of that values\n",
    "\n",
    "    :return: 6 data sets of X and Y\n",
    "    \"\"\"\n",
    "\n",
    "    dist = Counter(val for val in Y_data)\n",
    "    print('Total class distribution:', dict(dist))\n",
    "\n",
    "    Y_data.reset_index(drop=True, inplace=True)\n",
    "    X_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_ix = []\n",
    "    validate_ix = []\n",
    "    test_ix = []\n",
    "    for cls in dist.keys():\n",
    "        num_train = my_round(dist[cls] * train_size, base=mini_batch_size)\n",
    "        num_test = my_round(dist[cls] * test_size, base=mini_batch_size)\n",
    "\n",
    "        cls_targets = Y_data[Y_data == cls]\n",
    "\n",
    "        full_ixs = np.random.choice(cls_targets.index, size=num_train, replace=False)\n",
    "\n",
    "        train_ix += list(full_ixs)\n",
    "\n",
    "        cls_targets = cls_targets[~cls_targets.index.isin(full_ixs)]\n",
    "\n",
    "        full_ixs = np.random.choice(cls_targets.index, size=num_test, replace=False)\n",
    "\n",
    "        test_ix += list(full_ixs)\n",
    "\n",
    "        cls_targets = cls_targets[~cls_targets.index.isin(full_ixs)]\n",
    "\n",
    "        validate_ix += list(cls_targets.index)\n",
    "\n",
    "    X_train = X_data[train_ix].reset_index(drop=True)\n",
    "    Y_train = Y_data[train_ix].reset_index(drop=True)\n",
    "\n",
    "    X_validate = X_data[validate_ix].reset_index(drop=True)\n",
    "    Y_validate = Y_data[validate_ix].reset_index(drop=True)\n",
    "\n",
    "    X_test = X_data[test_ix].reset_index(drop=True)\n",
    "    Y_test = Y_data[test_ix].reset_index(drop=True)\n",
    "\n",
    "    print('Train class distribution:', dict(Counter(val for val in Y_train)))\n",
    "    print('Validate class distribution:', dict(Counter(val for val in Y_validate)))\n",
    "    print('Test class distribution:', dict(Counter(val for val in Y_test)))\n",
    "\n",
    "    return X_train, Y_train, X_validate, Y_validate, X_test, Y_test\n",
    "\n",
    "\n",
    "def parse_df_into_sets_by_tertiary_grouping(df, ter=\"ID\", y=\"Score\", x=\"text\", train_prop=.7, test_prop=.2):\n",
    "\n",
    "    ideal_train_size = math.floor(len(df)*train_prop)\n",
    "    ideal_test_size = math.floor(len(df)*test_prop)\n",
    "    ideal_val_size = len(df) - (ideal_train_size + ideal_test_size)\n",
    "\n",
    "    title_avg_count = df[ter].value_counts().mean()\n",
    "\n",
    "    titles = df[ter].unique().tolist()\n",
    "\n",
    "    train_titles = []\n",
    "    train_count = 0\n",
    "\n",
    "    while train_count <= ideal_train_size - title_avg_count:\n",
    "        title = np.random.choice(titles)\n",
    "        titles.remove(title)\n",
    "        train_titles.append(title)\n",
    "        train_count += len(df[df[ter] == title])\n",
    "\n",
    "    test_titles = []\n",
    "    test_count = 0\n",
    "\n",
    "    while test_count <= ideal_test_size - title_avg_count:\n",
    "        title = np.random.choice(titles)\n",
    "        titles.remove(title)\n",
    "        test_titles.append(title)\n",
    "        test_count += len(df[df[ter] == title]) \n",
    "\n",
    "    val_titles = titles\n",
    "    val_count = len(df[df[ter].isin(val_titles)])\n",
    "\n",
    "    print(\"Ideal train size is:\", ideal_train_size, \"whearas the actual is:\", train_count)\n",
    "    print(\"Ideal val size is:\", ideal_val_size, \"whearas the actual is:\", val_count)\n",
    "    print(\"Ideal test size is:\", ideal_test_size, \"whearas the actual is:\", test_count)\n",
    "\n",
    "    df_trn = df[df[ter].isin(train_titles)]\n",
    "    df_val = df[df[ter].isin(val_titles)]\n",
    "    df_tst = df[df[ter].isin(test_titles)]\n",
    "    \n",
    "    print(\"Train class distribution:\", df_trn[y].value_counts())\n",
    "    print(\"Val class distribution:\", df_val[y].value_counts())\n",
    "    print(\"Test class distribution:\", df_tst[y].value_counts())\n",
    "\n",
    "    return df_trn[x], df_trn[y], df_val[x], df_val[y], df_tst[x], df_tst[y]\n",
    "\n",
    "def balance_classes(X_data, Y_data, min_class_value=None):\n",
    "    \n",
    "    kes = Y_data.value_counts().keys().tolist()\n",
    "    \n",
    "    min_class = Y_data.value_counts().keys()[-1]\n",
    "    \n",
    "    if not min_class_value:\n",
    "        min_class_value = Y_data.value_counts().values[-1]\n",
    "    \n",
    "    all_ix = []\n",
    "            \n",
    "    for ke in kes:\n",
    "        ke_indexes = Y_data[Y_data == ke].index.tolist()\n",
    "        if len(ke_indexes) == min_class_value:\n",
    "            all_ix += ke_indexes\n",
    "        else:\n",
    "            all_ix += list(np.random.choice(ke_indexes, size=min_class_value, replace=False))\n",
    "        \n",
    "    X_data = X_data[all_ix]\n",
    "    Y_data = Y_data[all_ix]\n",
    "    \n",
    "    print(\"Y class distribution:\", Y_data.value_counts())\n",
    "    \n",
    "    return X_data, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     16106\n",
       "Positive    14302\n",
       "Negative     5224\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total class distribution: {'Positive': 14302, 'Neutral': 16106, 'Negative': 5224}\n",
      "Train class distribution: {'Positive': 1204, 'Neutral': 1356, 'Negative': 440}\n",
      "Validate class distribution: {'Positive': 1204, 'Neutral': 1356, 'Negative': 440}\n",
      "Test class distribution: {'Positive': 11894, 'Neutral': 13394, 'Negative': 4344}\n",
      "3 classes\n"
     ]
    }
   ],
   "source": [
    "# Unbalanced\n",
    "X_train, Y_train, X_validate, Y_validate, X_test, Y_test = split_dataset_into_even_class_distributions(X_data=df['Snippet'],\n",
    "                                                                                                       Y_data=df['Sentiment'], \n",
    "                                                                                                       train_size=3000/len(df), \n",
    "                                                                                                       test_size=1-(6000/len(df)),\n",
    "                                                                                                       mini_batch_size=1)\n",
    "\n",
    "df_trn = pd.DataFrame(np.array([Y_train, X_train]).T, columns=['label', 'text'])\n",
    "df_val = pd.DataFrame(np.array([Y_validate, X_validate]).T, columns=['label', 'text'])\n",
    "df_tst = pd.DataFrame(np.array([Y_test, X_test]).T, columns=['label', 'text'])\n",
    "\n",
    "N_CLASSES = len(Y_train.value_counts())\n",
    "print(N_CLASSES, \"classes\")\n",
    "\n",
    "for size in [100, 300, 1000]:\n",
    "    df_trn.sample(n=size*N_CLASSES).to_csv(subtask_dir / (\"fair_unbalanced_\"+str(size)) / \"train.csv\", index=False, quoting=csv.QUOTE_ALL, encoding='utf-8')\n",
    "    df_val.to_csv(subtask_dir / (\"fair_unbalanced_\"+str(size)) / \"validate.csv\", index=False, quoting=csv.QUOTE_ALL, encoding='utf-8')\n",
    "    df_tst.to_csv(subtask_dir / (\"fair_unbalanced_\"+str(size)) / \"test.csv\", index=False, quoting=csv.QUOTE_ALL, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total class distribution: {'Positive': 14302, 'Neutral': 16106, 'Negative': 5224}\n",
      "Train class distribution: {'Positive': 2860, 'Neutral': 3221, 'Negative': 1045}\n",
      "Validate class distribution: {'Positive': 2861, 'Neutral': 3221, 'Negative': 1045}\n",
      "Test class distribution: {'Positive': 8581, 'Neutral': 9664, 'Negative': 3134}\n",
      "Neutral     3221\n",
      "Positive    2860\n",
      "Negative    1045\n",
      "Name: Sentiment, dtype: int64\n",
      "Neutral     9664\n",
      "Positive    8581\n",
      "Negative    3134\n",
      "Name: Sentiment, dtype: int64\n",
      "Y class distribution: Neutral     1045\n",
      "Negative    1045\n",
      "Positive    1045\n",
      "Name: Sentiment, dtype: int64\n",
      "Y class distribution: Neutral     3000\n",
      "Negative    3000\n",
      "Positive    3000\n",
      "Name: Sentiment, dtype: int64\n",
      "3 classes\n",
      "Y class distribution: Negative    100\n",
      "Neutral     100\n",
      "Positive    100\n",
      "Name: Sentiment, dtype: int64\n",
      "Y class distribution: Neutral     300\n",
      "Negative    300\n",
      "Positive    300\n",
      "Name: Sentiment, dtype: int64\n",
      "Y class distribution: Neutral     1000\n",
      "Negative    1000\n",
      "Positive    1000\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balanced\n",
    "X_train, Y_train, X_validate, Y_validate, X_test, Y_test = split_dataset_into_even_class_distributions(X_data=df['Snippet'],\n",
    "                                                                                                       Y_data=df['Sentiment'], \n",
    "                                                                                                       train_size=.2, \n",
    "                                                                                                       test_size=.6,\n",
    "                                                                                                       mini_batch_size=1)\n",
    "\n",
    "print(Y_train.value_counts())\n",
    "print(Y_test.value_counts())\n",
    "\n",
    "X_validate, Y_validate = balance_classes(X_validate, Y_validate, min_class_value=None)\n",
    "X_test, Y_test = balance_classes(X_test, Y_test, min_class_value=3000)\n",
    "\n",
    "df_val = pd.DataFrame(np.array([Y_validate, X_validate]).T, columns=['label', 'text'])\n",
    "df_tst = pd.DataFrame(np.array([Y_test, X_test]).T, columns=['label', 'text'])\n",
    "\n",
    "N_CLASSES = len(Y_train.value_counts())\n",
    "print(N_CLASSES, \"classes\")\n",
    "\n",
    "for size in [100, 300, 1000]:\n",
    "    X_train_sub, Y_train_sub = balance_classes(X_train, Y_train, min_class_value=size)\n",
    "    df_trn = pd.DataFrame(np.array([Y_train_sub, X_train_sub]).T, columns=['label', 'text'])\n",
    "    df_trn.to_csv(subtask_dir / (\"fair_balanced_\"+str(size)) / \"train.csv\", index=False, quoting=csv.QUOTE_ALL, encoding='utf-8')\n",
    "    df_val.to_csv(subtask_dir / (\"fair_balanced_\"+str(size)) / \"validate.csv\", index=False, quoting=csv.QUOTE_ALL, encoding='utf-8')\n",
    "    df_tst.to_csv(subtask_dir / (\"fair_balanced_\"+str(size)) / \"test.csv\", index=False, quoting=csv.QUOTE_ALL, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     1000\n",
       "Negative    1000\n",
       "Positive    1000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(subtask_dir / (\"fair_balanced_\"+str(1000)) / \"train.csv\")\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Harper, you may not think Justin's ready, but urine over your head.\",\n",
       " 'July 27th 2015- the day all the women who find Dean Ambrose attractive died',\n",
       " '@Zwelinzima1 do we really have to march every time we have issues to deal with?   Marchers clash at Cosatu rally http://t.co/JN9zwWMp',\n",
       " 'Call us superstitious...our condo does not have a 13th floor. Some Wiki thoughts on the origin of that tradition: http://t.co/BnGepbeC',\n",
       " \"@Lrihendry @ChristieC733 what's scary is that it was only 5-4. Like our SCOTUS, Irving may flip on one vote.\",\n",
       " 'Once again Democrats spent all night and this morning trying to talk down the stock market...whatever happens there can be no blank check!',\n",
       " 'stupid cable took the CW Network away why?it better be back by october 11th if not we are going to have a problem lol #tvd',\n",
       " \"Embarrassing. Rams cut Alexander. Yes I know he's from Mizzou. But c'mon. Chiefs D makes unknowns look like pro bowlers.\",\n",
       " 'Steve may in fact be the biggest pussy in Big Brother history #BB17',\n",
       " 'Poor Bruce Springsteen: 1st Swan co-opts Badlands; then Abbott adopts the Wrecking Ball title. When will Aussie politicians leave him alone?']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 'Negative']['text'].sample(n=10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_100\\test.csv\n",
      "Negative    3000\n",
      "Positive    3000\n",
      "Neutral     3000\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_100\\train.csv\n",
      "Negative    100\n",
      "Neutral     100\n",
      "Positive    100\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_100\\validate.csv\n",
      "Negative    1046\n",
      "Positive    1046\n",
      "Neutral     1046\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_300\\test.csv\n",
      "Negative    3000\n",
      "Positive    3000\n",
      "Neutral     3000\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_300\\train.csv\n",
      "Positive    300\n",
      "Negative    300\n",
      "Neutral     300\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_300\\validate.csv\n",
      "Negative    1046\n",
      "Positive    1046\n",
      "Neutral     1046\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_1000\\test.csv\n",
      "Negative    3000\n",
      "Positive    3000\n",
      "Neutral     3000\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_1000\\train.csv\n",
      "Negative    1000\n",
      "Positive    1000\n",
      "Neutral     1000\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_balanced_1000\\validate.csv\n",
      "Negative    1046\n",
      "Positive    1046\n",
      "Neutral     1046\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_100\\test.csv\n",
      "Neutral     13399\n",
      "Positive    11892\n",
      "Negative     4347\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_100\\train.csv\n",
      "Neutral     139\n",
      "Positive    111\n",
      "Negative     50\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_100\\validate.csv\n",
      "Neutral     1356\n",
      "Positive    1204\n",
      "Negative     440\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_300\\test.csv\n",
      "Neutral     13399\n",
      "Positive    11892\n",
      "Negative     4347\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_300\\train.csv\n",
      "Neutral     414\n",
      "Positive    345\n",
      "Negative    141\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_300\\validate.csv\n",
      "Neutral     1356\n",
      "Positive    1204\n",
      "Negative     440\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_1000\\test.csv\n",
      "Neutral     13399\n",
      "Positive    11892\n",
      "Negative     4347\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_1000\\train.csv\n",
      "Neutral     1356\n",
      "Positive    1204\n",
      "Negative     440\n",
      "Name: label, dtype: int64\n",
      "C:\\Users\\usherwoodpe\\Documents\\bibliotecas\\low_shot_tl\\datasets\\semeval\\Subtask_A\\fair_unbalanced_1000\\validate.csv\n",
      "Neutral     1356\n",
      "Positive    1204\n",
      "Negative     440\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#FIXUP\n",
    "\n",
    "folders = [\"fair_balanced_100\", \"fair_balanced_300\", \"fair_balanced_1000\", \"fair_unbalanced_100\", \"fair_unbalanced_300\", \"fair_unbalanced_1000\"]\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(subtask_dir / folder)\n",
    "    for file in files:\n",
    "        df = pd.read_csv(subtask_dir / folder / file)\n",
    "        print(subtask_dir / folder / file)\n",
    "        df[\"label\"] = df[\"label\"].replace(\"negative\",\"Negative\").replace(\"positive\", \"Positive\").replace(\"neutral\", \"Neutral\")\n",
    "        print(df['label'].value_counts())\n",
    "        df.to_csv(subtask_dir / folder / file, index=False, quoting=csv.QUOTE_ALL, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 'Project X is the best film ever made and someone with money needs to have one, like this Friday. #makeithappen',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'Just found out we have 91 Appointments n we are shooting for 120 on Monday - Huntsville, AL are you ready for us?!?!  #NMAE @lancomeparis',\n",
       " nan]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn[df_trn['label'] == 'Negative']['text'].sample(n=10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
